{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46b5553",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Replace YOUR_API_SECRET_KEY with your actual OpenAI API secret key\n",
    "api_secret_key = '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'\n",
    "\n",
    "# The API endpoint for GPT-3\n",
    "url = 'https://api.openai.com/'\n",
    "\n",
    "# The parameters for the request\n",
    "# You can specify the model and the prompt\n",
    "prompt = 'hyperdipillemia morpidopesity, diabetic neuropathy?'\n",
    "model = 'text-davinci-002'\n",
    "params = {'prompt': prompt, 'model': model, 'max_tokens': 100}\n",
    "\n",
    "# Set the headers for the request\n",
    "headers = {'Content-Type': 'application/json', 'Authorization': f'Bearer {api_secret_key}'}\n",
    "\n",
    "# Make the request\n",
    "response = requests.post(url, json=params, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Print the generated text\n",
    "    print(response.json()['choices'][0]['text'])\n",
    "else:\n",
    "    print(f'Error: {response.status_code}')\n",
    "    print(response.json())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce737ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Replace YOUR_API_KEY with your actual API key\n",
    "api_key = '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'\n",
    "\n",
    "# Specify the word or phrase you want to search for\n",
    "prompt = 'find the meaning of life'\n",
    "\n",
    "# Specify the model to use\n",
    "model = 'davinci-codex'\n",
    "\n",
    "# Set the maximum number of completions to generate\n",
    "max_tokens = 50\n",
    "\n",
    "# Set the endpoint URL\n",
    "endpoint = f'https://api.openai.com/v1/engines/{model}/completions'\n",
    "\n",
    "# Set the headers for the API request\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': f'Bearer {api_key}'\n",
    "}\n",
    "\n",
    "# Set the request body\n",
    "data = {\n",
    "    'prompt': prompt,\n",
    "    'max_tokens': max_tokens\n",
    "}\n",
    "\n",
    "# Send the request to the API\n",
    "response = requests.post(endpoint, headers=headers, json=data)\n",
    "\n",
    "# Print the response\n",
    "print(response.json())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670c41a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = \"\"\n",
    "\n",
    "# openai.api_key = os.getenv('')\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"code-davinci-002\",x\n",
    "  prompt=\"\\\"\\\"\\\"\\nUtil exposes the following:\\nutil.openai() -> authenticates & returns the openai module, which has the following functions:\\nopenai.Completion.create(\\n    prompt=\\\"<my prompt>\\\", # The prompt to start completing from\\n    max_tokens=123, # The max number of tokens to generate\\n    temperature=1.0 # A measure of randomness\\n    echo=True, # Whether to return the prompt in addition to the generated completion\\n)\\n\\\"\\\"\\\"\\nimport util\\n\\\"\\\"\\\"\\nCreate an OpenAI completion starting from the prompt \\\"Once upon an AI\\\", no more than 5 tokens. Does not include the prompt.\\n\\\"\\\"\\\"\\n\",\n",
    "  temperature=0,\n",
    "  max_tokens=64,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    "  stop=[\"\\\"\\\"\\\"\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215ba998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59c5659d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the prompt: Please correct and tag the word hyperdililimia in medical/clinical terms\n",
      ".\n",
      "\n",
      "I am not sure if this is a medical term or not.\n",
      "\n",
      "Thanks.\n",
      "\n",
      "I am not sure if this is a medical term or not. Thanks.\n",
      "\n",
      "Selected response from:\n",
      "\n",
      "xxxLia Fail\n",
      "\n",
      "Spain\n",
      "\n",
      "Local time: 13:24\n",
      "\n",
      "SpainLocal time:\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "openai.api_key = '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'\n",
    "# Get user input for the prompt\n",
    "prompt = input(\"Enter the prompt: \")\n",
    "# Use the user input as the prompt in the API request\n",
    "response = openai.Completion.create(\n",
    "    model=\"code-davinci-002\",\n",
    "    prompt=prompt,\n",
    "    temperature=0.05,\n",
    "    max_tokens=100,\n",
    "    top_p=0.65,\n",
    "    frequency_penalty=0.01,\n",
    "    presence_penalty=0.0,\n",
    "    stop=[\"\\\"\\\"\\\"\"]\n",
    ")\n",
    "# Print the generated completions\n",
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c45baa4b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "You exceeded your current quota, please check your plan and billing details.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m openai\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msk-Tc9mkx3yreqPXivuzjsNT3BlbkFJ1zZIb8lAINMd0ygKOB0z\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      5\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCONFIDENTIALITY NOTICE: transmission may contain confidential information belonging to the sender, which is legally privileged, The information is intended only for the use of the individual or entity named above. If you are not the intended recipient, you are hereby notified that any disclosure, copying, distribution, or the taking of any action is strictly prohibited. Please provide any medicines to which the patient is allergic: Clindamycin [DRUG], metmafin[DRUG], penicillin V, Sulfa ( Sulfa- namide Antibiotics) Please provide a list of any medications the patient may be taking, including over the counter (If available): See Attached Please provide any health conditions the patient has: Arghristis Asthma, spellcheck_clinica, diabetes mellitus GERD, hyperdipillemia morpidopesity, diabetic neuropathy, Vitamin Deleficiency\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 7\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext-davinci-002\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPlease summarize the text and extract the drugs, diseases, symptoms, and diagnosis mentioned in it. Text: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtext\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\n\u001b[0;32m     13\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\api_resources\\completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\api_requestor.py:227\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    208\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    215\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    216\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    217\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[0;32m    218\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[0;32m    219\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    225\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[0;32m    226\u001b[0m     )\n\u001b[1;32m--> 227\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\api_requestor.py:620\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    612\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    613\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    614\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    615\u001b[0m         )\n\u001b[0;32m    616\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[0;32m    617\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    619\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 620\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    621\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    623\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    624\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    625\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    626\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    627\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\api_requestor.py:680\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    678\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[0;32m    681\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[0;32m    682\u001b[0m     )\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details."
     ]
    }
   ],
   "source": [
    "\n",
    "import openai\n",
    "import os\n",
    "openai.api_key = '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'\n",
    "\n",
    "text = \"Can you correct anmorbidocity\"\n",
    "response = openai.Completion.create(\n",
    "    engine=\"text-davinci-002\",\n",
    "    prompt=f\"Please summarize the text and extract the drugs, diseases, symptoms, and diagnosis mentioned in it. Text: {text}\",\n",
    "    max_tokens=100,\n",
    "    stop=[\".\"],\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "print(response[\"choices\"][0][\"text\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d453ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Use the API key for your OpenAI account\n",
    "openai.api_key = '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'\n",
    "\n",
    "# Define the medical text you want to tag\n",
    "text = \"Arghristis Asthma, spellcheck_clinica, diabetes mellitus GERD, hyperdipillemia morpidopesity, diabetic neuropathy, Vitamin Deleficiency\"\n",
    "\n",
    "# Use GPT-3 to tag the medical text\n",
    "response = openai.Completion.create(\n",
    "    engine=\"text-davinci-002\",\n",
    "    prompt=(f\"Please tag the following medical text in tabular format:\\n{text}\\n\\n\"\n",
    "            \"Format: [Tag]:[Text]\\n\"\n",
    "            \"Example: Disease:Hypertension\"),\n",
    "    max_tokens=1024,\n",
    "    n = 1,\n",
    "    stop=None,\n",
    "    temperature=0.5,\n",
    ")\n",
    "\n",
    "# Print the tagged text\n",
    "tagged_text = response.choices[0].text\n",
    "print(tagged_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940ae849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.chdir('C:/Users/p_adi/OneDrive/Desktop')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdf15d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('all_chem_df.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61977398",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data['tags'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd31fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('output_updated.csv')\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6be0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2cf9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "x1 = reduce(lambda a, b : a+ \" \" +str(b), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93c0500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363b80f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "# Tokenize the words column in the dataframe\n",
    "data1[\"words\"] = data1[\"word\"].apply(lambda x: word_tokenize(x))\n",
    "\n",
    "# Tokenize the list of words\n",
    "list_of_words = word_tokenize(x1)\n",
    "\n",
    "# Iterate through the list of words and check if each word is present in the tokenized words column\n",
    "for word in list_of_words:\n",
    "    if word not in data1[\"words\"].sum():\n",
    "        data1[\"words\"].append(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed4ec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1[\"new_words\"] = data1[\"word\"].apply(lambda x: word_tokenize(x))\n",
    "\n",
    "# Iterate through the list of words and check if each word is present in the tokenized words column\n",
    "for word in list_of_words:\n",
    "    if word not in data1[\"new_words\"].sum():\n",
    "        data1[\"new_words\"].append(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51974b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.chdir('C:/Users/p_adi/OneDrive/Desktop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fcd0346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'description', 'medical_specialty', 'sample_name',\n",
       "       'transcription', 'keywords'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('mtsamples.csv')\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e582ac2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUBJECTIVE:,  This 23-year-old white female pr...</td>\n",
       "      <td>allergy / immunology, allergic rhinitis, aller...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PAST MEDICAL HISTORY:, He has difficulty climb...</td>\n",
       "      <td>bariatrics, laparoscopic gastric bypass, weigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HISTORY OF PRESENT ILLNESS: , I have seen ABC ...</td>\n",
       "      <td>bariatrics, laparoscopic gastric bypass, heart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-D M-MODE: , ,1.  Left atrial enlargement wit...</td>\n",
       "      <td>cardiovascular / pulmonary, 2-d m-mode, dopple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.  The left ventricular cavity size and wall ...</td>\n",
       "      <td>cardiovascular / pulmonary, 2-d, doppler, echo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       transcription  \\\n",
       "0  SUBJECTIVE:,  This 23-year-old white female pr...   \n",
       "1  PAST MEDICAL HISTORY:, He has difficulty climb...   \n",
       "2  HISTORY OF PRESENT ILLNESS: , I have seen ABC ...   \n",
       "3  2-D M-MODE: , ,1.  Left atrial enlargement wit...   \n",
       "4  1.  The left ventricular cavity size and wall ...   \n",
       "\n",
       "                                            keywords  \n",
       "0  allergy / immunology, allergic rhinitis, aller...  \n",
       "1  bariatrics, laparoscopic gastric bypass, weigh...  \n",
       "2  bariatrics, laparoscopic gastric bypass, heart...  \n",
       "3  cardiovascular / pulmonary, 2-d m-mode, dopple...  \n",
       "4  cardiovascular / pulmonary, 2-d, doppler, echo...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_data = data[['transcription', 'keywords']]\n",
    "w_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330280d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_qa_pairs(df, transcript_column, keyword_column):\n",
    "    transcripts = df[transcript_column].tolist()\n",
    "    keywords = df[keyword_column].tolist()\n",
    "    qa_pairs = []\n",
    "    for transcript, keyword in zip(transcripts, keywords):\n",
    "        qa_pairs.append(\"<QUESTION> \" + str(transcript) + \" <ANSWER> \" + str(keyword))\n",
    "    return qa_pairs\n",
    "\n",
    "\n",
    "qa_pairs = extract_qa_pairs(w_data, 'transcription', 'keywords')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a757c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5878c29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Load ClinicalBERT tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"emorynlp/clinical-bert-base\")\n",
    "model = AutoModel.from_pretrained(\"emorynlp/clinical-bert-base\")\n",
    "\n",
    "# Define a function to generate question-answer pairs\n",
    "def generate_qa_pairs(transcription, keyword):\n",
    "    # Encode the input text\n",
    "    input_ids = tokenizer.encode(transcription, return_tensors='pt', add_special_tokens=True)\n",
    "\n",
    "    # Pass the input through the model to generate a summary\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "        last_hidden_states = outputs[0]  # Use the last hidden state for QA generation\n",
    "        summary = tokenizer.decode(torch.argmax(last_hidden_states[0], dim=1))\n",
    "\n",
    "    # Format the output as a question-answer pair\n",
    "    return \"<QUESTION> \" + transcription + \" <ANSWER> \" + keyword\n",
    "\n",
    "# Call the function on your data to generate QA pairs\n",
    "transcriptions = ...  # List of transcriptions from your data\n",
    "keywords = ...  # List of keywords from your data\n",
    "qa_pairs = [generate_qa_pairs(transcription, keyword) for transcription, keyword in zip(transcriptions, keywords)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e667599f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10ee04b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ClinicalBERTForQuestionAnswering' from 'transformers' (C:\\Users\\p_adi\\anaconda3\\lib\\site-packages\\transformers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ClinicalBERTForQuestionAnswering, ClinicalBERTTokenizer\n\u001b[0;32m      4\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memilyalsentzer/ClinicalBERT-Base\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m ClinicalBERTForQuestionAnswering\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'ClinicalBERTForQuestionAnswering' from 'transformers' (C:\\Users\\p_adi\\anaconda3\\lib\\site-packages\\transformers\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import ClinicalBERTForQuestionAnswering, ClinicalBERTTokenizer\n",
    "\n",
    "model_name = \"emilyalsentzer/ClinicalBERT-Base\"\n",
    "model = ClinicalBERTForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = ClinicalBERTTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2682160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the input text\n",
    "text = \"A 23-year-old white female presents with complaints of seasonal allergy symptoms.\"\n",
    "question = \"What type of allergy symptoms does the patient have?\"\n",
    "\n",
    "encoded_text = tokenizer.encode_plus(text, question, return_tensors='pt')\n",
    "input_ids = encoded_text['input_ids']\n",
    "attention_mask = encoded_text['attention_mask']\n",
    "\n",
    "# Generate a prediction for the answer\n",
    "with torch.no_grad():\n",
    "    output = model(input_ids, attention_mask=attention_mask)\n",
    "    answer_start = torch.argmax(output[0])\n",
    "    answer_end = torch.argmax(output[1])\n",
    "    answer = tokenizer.decode(input_ids[0, answer_start:answer_end + 1])\n",
    "\n",
    "# Print the answer\n",
    "print(\"Answer: \", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac763dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8744c3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>desc</th>\n",
       "      <th>prevent</th>\n",
       "      <th>cause</th>\n",
       "      <th>symptom</th>\n",
       "      <th>acompany</th>\n",
       "      <th>cure_department</th>\n",
       "      <th>cure_way</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alveolar proteinosis</td>\n",
       "      <td>alveolar proteinosis (pap), also known as rose...</td>\n",
       "      <td>1, to avoid infection with mycobacterial disea...</td>\n",
       "      <td>the cause is unknown, and it is speculated tha...</td>\n",
       "      <td>['cyanosis', 'chest pain', 'breathing difficul...</td>\n",
       "      <td>['multiple lung infections']</td>\n",
       "      <td>['internal medicine', 'respiratory medicine']</td>\n",
       "      <td>['bronchoalveolar lavage']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pertussis</td>\n",
       "      <td>pertussis (whoopingcough) is an acute respirat...</td>\n",
       "      <td>1, control of the source of infection: in the ...</td>\n",
       "      <td>(1) causes of the disease the pathogen is b. p...</td>\n",
       "      <td>['hanging sound when inhaling', 'sexual cough'...</td>\n",
       "      <td>['lung atelect']</td>\n",
       "      <td>['pediatrics', 'pediatric medicine']</td>\n",
       "      <td>['medical treatment', 'supportive treatment']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>benzene poisoning</td>\n",
       "      <td>benzene is an aromatic hydrocarbon compound ob...</td>\n",
       "      <td>for patients with acute poisoning, you can imm...</td>\n",
       "      <td>inhalation of benzene vapor or skin contact wi...</td>\n",
       "      <td>['disgusting', 'twitching', 'feeling obstacle']</td>\n",
       "      <td>['anemia']</td>\n",
       "      <td>['emergency department']</td>\n",
       "      <td>['medical treatment', 'supportive treatment']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asthmatic bronchitis</td>\n",
       "      <td>asthmatoid bronchitis, also known as asthmatic...</td>\n",
       "      <td>according to the above section, for children w...</td>\n",
       "      <td>because a variety of viral and bacterial infec...</td>\n",
       "      <td>['shrubbing's wheezing', 'wheeling sound', 'ci...</td>\n",
       "      <td>['bronchial asthma']</td>\n",
       "      <td>['internal medicine', 'respiratory medicine']</td>\n",
       "      <td>['medical treatment', 'supportive treatment']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adult respiratory distress syndrome</td>\n",
       "      <td>adult respiratory distress syndrome, abbreviat...</td>\n",
       "      <td>patients with high-risk should be closely obse...</td>\n",
       "      <td>suppurative infections can cause bacterial tox...</td>\n",
       "      <td>['difficulty breathing', 'purple', 'cardiac re...</td>\n",
       "      <td>['bacterial pneumonia']</td>\n",
       "      <td>['internal medicine', 'respiratory medicine']</td>\n",
       "      <td>['medical treatment', 'supportive treatment']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  name  \\\n",
       "0                 alveolar proteinosis   \n",
       "1                            pertussis   \n",
       "2                    benzene poisoning   \n",
       "3                 asthmatic bronchitis   \n",
       "4  adult respiratory distress syndrome   \n",
       "\n",
       "                                                desc  \\\n",
       "0  alveolar proteinosis (pap), also known as rose...   \n",
       "1  pertussis (whoopingcough) is an acute respirat...   \n",
       "2  benzene is an aromatic hydrocarbon compound ob...   \n",
       "3  asthmatoid bronchitis, also known as asthmatic...   \n",
       "4  adult respiratory distress syndrome, abbreviat...   \n",
       "\n",
       "                                             prevent  \\\n",
       "0  1, to avoid infection with mycobacterial disea...   \n",
       "1  1, control of the source of infection: in the ...   \n",
       "2  for patients with acute poisoning, you can imm...   \n",
       "3  according to the above section, for children w...   \n",
       "4  patients with high-risk should be closely obse...   \n",
       "\n",
       "                                               cause  \\\n",
       "0  the cause is unknown, and it is speculated tha...   \n",
       "1  (1) causes of the disease the pathogen is b. p...   \n",
       "2  inhalation of benzene vapor or skin contact wi...   \n",
       "3  because a variety of viral and bacterial infec...   \n",
       "4  suppurative infections can cause bacterial tox...   \n",
       "\n",
       "                                             symptom  \\\n",
       "0  ['cyanosis', 'chest pain', 'breathing difficul...   \n",
       "1  ['hanging sound when inhaling', 'sexual cough'...   \n",
       "2    ['disgusting', 'twitching', 'feeling obstacle']   \n",
       "3  ['shrubbing's wheezing', 'wheeling sound', 'ci...   \n",
       "4  ['difficulty breathing', 'purple', 'cardiac re...   \n",
       "\n",
       "                       acompany  \\\n",
       "0  ['multiple lung infections']   \n",
       "1              ['lung atelect']   \n",
       "2                    ['anemia']   \n",
       "3          ['bronchial asthma']   \n",
       "4       ['bacterial pneumonia']   \n",
       "\n",
       "                                 cure_department  \\\n",
       "0  ['internal medicine', 'respiratory medicine']   \n",
       "1           ['pediatrics', 'pediatric medicine']   \n",
       "2                       ['emergency department']   \n",
       "3  ['internal medicine', 'respiratory medicine']   \n",
       "4  ['internal medicine', 'respiratory medicine']   \n",
       "\n",
       "                                        cure_way  \n",
       "0                     ['bronchoalveolar lavage']  \n",
       "1  ['medical treatment', 'supportive treatment']  \n",
       "2  ['medical treatment', 'supportive treatment']  \n",
       "3  ['medical treatment', 'supportive treatment']  \n",
       "4  ['medical treatment', 'supportive treatment']  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.read_excel('medical_knowledge_base.xlsx')\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52efbbdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>postural hypotension</td>\n",
       "      <td>disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>parkinson ' s disease</td>\n",
       "      <td>disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>systolic orthostatic hypotension</td>\n",
       "      <td>disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>orthostatic hypotension</td>\n",
       "      <td>disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reduced the supine systolic and diastolic bloo...</td>\n",
       "      <td>disease</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                word    label\n",
       "0                               postural hypotension  disease\n",
       "1                              parkinson ' s disease  disease\n",
       "2                   systolic orthostatic hypotension  disease\n",
       "3                            orthostatic hypotension  disease\n",
       "4  reduced the supine systolic and diastolic bloo...  disease"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = pd.read_csv('output_updated.csv')\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a653712",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data1[['name', 'desc']]\n",
    "new_row = {'name':'popaverus', 'desc':'ahshdf kdsfflkjdo lsdljfdk '}\n",
    "data1 = data1.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33a5ad22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>popaverus</td>\n",
       "      <td>ahshdf kdsfflkjdo lsdljfdk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name                         desc\n",
       "674  popaverus  ahshdf kdsfflkjdo lsdljfdk "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1[data1.name== 'popaverus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a8ffa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def check_and_append(data2, data1):\n",
    "    for index, row in data1.iterrows():\n",
    "        name = row['name']\n",
    "        found = False\n",
    "        for index1, row1 in data2.iterrows():\n",
    "            if name in row1['word']:\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            data2 = data2.append({'word': 'name', 'label': 'Unknown'}, ignore_index=True)\n",
    "    return data2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a0864e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fde2fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e26dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
