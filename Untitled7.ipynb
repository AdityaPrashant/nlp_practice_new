{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a7193ab",
   "metadata": {},
   "source": [
    "# NER Word Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290ed617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#Data visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e828677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C:/Users/p_adi/OneDrive/Desktop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62da4f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sample_train_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca83b908",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['index'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950ae2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57039053",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=\"generic_names\", keep=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baec718",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac199fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('df_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90be50a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cce568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "def pos_tag_column(df, column):\n",
    "    \"\"\"\n",
    "    Perform part-of-speech tagging on a column of text data in a Pandas DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): a Pandas DataFrame\n",
    "    column (str): the name of the column containing the text data\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: a new Pandas DataFrame with an additional column for the POS tags\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize an empty list to store the POS tags\n",
    "    pos_tags = []\n",
    "    \n",
    "    # Iterate over the text data in the specified column\n",
    "    for text in df[column]:\n",
    "        # Tokenize the text\n",
    "        words = nltk.word_tokenize(text)\n",
    "        \n",
    "        # Use the NLTK pos_tag function to tag the words\n",
    "        tags = nltk.pos_tag(words)\n",
    "        \n",
    "        # Add the tags to the list\n",
    "        pos_tags.append(tags)\n",
    "    \n",
    "    # Add the POS tags to the DataFrame as a new column\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47546457",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pos_tags'] = pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e2acee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "def hash_word(word):\n",
    "    # Uses the sha256 hash function to generate a hash code for the word\n",
    "    return hashlib.sha256(word.encode()).hexdigest()\n",
    "\n",
    "def search_hashes(hashes, word_to_find):\n",
    "    # Converts the word to find to its hash code\n",
    "    word_hash = hash_word(word_to_find)\n",
    "\n",
    "    # Iterates through the list of hashes and returns True if the\n",
    "    # word_hash is found in the list, False otherwise\n",
    "    for h in hashes:\n",
    "        if h == word_hash:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Example usage\n",
    "\n",
    "word_list = ['cholestrol', 'hyperlipidemia', 'Vigran', 'Farxiga','kuphosis', \n",
    "             'Deficiency', 'bening-hypertension', 'Arthritis']\n",
    "hashes = [hash_word(w) for w in word_list]\n",
    "\n",
    "\n",
    "\n",
    "print(search_hashes(hashes, 'hyperdipillemia')) # should print True\n",
    "print(search_hashes(hashes, 'Farxija'))   # should print False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a99557",
   "metadata": {},
   "outputs": [],
   "source": [
    "['morpidopesity', 'metholienate', 'chelesteral', 'hyperdipillemia', 'hyperlifichesmia','folliaded',\n",
    "                'Dratactive','towastatin', 'chelesteral', 'patision', 'Oregozale', 'Vigran', 'Farxija',\n",
    "               'puphosis', 'Deleficiency', 'besignhypertension', 'Arghristis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b722b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "def compare_hashes(string, hash_list):\n",
    "    # Calculate the hash of the input string\n",
    "    string_hash = hashlib.md5(string.encode()).hexdigest()\n",
    "\n",
    "    # Compare the input hash to each hash in the list\n",
    "    similarities = []\n",
    "    for h in hash_list:\n",
    "        similarity = 0\n",
    "        for i, c in enumerate(string_hash):\n",
    "            if c == h[i]:\n",
    "                similarity += 1\n",
    "        similarities.append(similarity)\n",
    "\n",
    "    # Calculate the percentage similarity\n",
    "    max_length = max(len(string_hash), max(map(len, hash_list)))\n",
    "    percent_similarities = [ (similarity/max_length) * 100 for similarity in similarities]\n",
    "    \n",
    "    return percent_similarities\n",
    "\n",
    "# Example usage\n",
    "string = \"example\"\n",
    "hash_list = [\"5d41402abc4b2a76b9719d911017c592\", \"37b51d194a7513e45b56f6524f2d51f2\"]\n",
    "percent_similarities = compare_hashes(string, hash_list)\n",
    "print(percent_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5a93b88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.25, 4.6875]\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "\n",
    "def compare_hashes(string, hash_list):\n",
    "    # Calculate the hash of the input string\n",
    "    string_hash = hashlib.md5(string.encode()).hexdigest()\n",
    "\n",
    "    # Compare the input hash to each hash in the list\n",
    "    similarities = []\n",
    "    for h in hash_list:\n",
    "        similarity = 0\n",
    "        for i, c in enumerate(string_hash):\n",
    "            if c == h[i]:\n",
    "                similarity += 1\n",
    "        similarities.append(similarity)\n",
    "\n",
    "    # Calculate the percentage similarity\n",
    "    max_length = max(len(string_hash), max(map(len, hash_list)))\n",
    "    percent_similarities = [ (similarity/max_length) * 100 for similarity in similarities]\n",
    "    \n",
    "    return percent_similarities\n",
    "\n",
    "\n",
    "def hash_words(words_list):\n",
    "    return list(map(lambda word: hashlib.sha256(word.encode()).hexdigest(), words_list))\n",
    "\n",
    "# Example usage\n",
    "words_list = [\"potassium\",\"besignhypertension\"]\n",
    "hashed_words = hash_words(words_list)\n",
    "\n",
    "# Example usage\n",
    "string = \"patision\"\n",
    "hash_list = hashed_words\n",
    "\n",
    "# [\"5d41402abc4b2a76b9719d911017c592\", \"37b51d194a7513e45b56f6524f2d51f2\"]\n",
    "\n",
    "percent_similarities = compare_hashes(string, hash_list)\n",
    "print(percent_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1175d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('potassium', 5)\n"
     ]
    }
   ],
   "source": [
    "import Levenshtein as lev\n",
    "\n",
    "def nearest_match(word, word_list):\n",
    "    distances = []\n",
    "    for w in word_list:\n",
    "        distances.append((w, lev.distance(word, w)))\n",
    "    return min(distances, key=lambda x: x[1])\n",
    "\n",
    "# Example usage\n",
    "word = \"patision\"\n",
    "word_list = [\"benign-hypertension\",\"morbid-obesity\",\"hyperlipidemia\", \"hypertension\", \"potassium\"]\n",
    "nearest_word = nearest_match(word, word_list)\n",
    "print(nearest_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c42b455d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nearest match for morpidopesity is ['morbid-obesity']\n",
      "The nearest match for dag is ['dog']\n",
      "The nearest match for besignhypertension is ['benign-hypertension']\n",
      "The nearest match for fush is ['fish']\n",
      "patision\n",
      "The nearest match for patision is ['potassium', 5]\n"
     ]
    }
   ],
   "source": [
    "## Code for listing wrongly searched words\n",
    "\n",
    "import difflib\n",
    "import Levenshtein as lev\n",
    "\n",
    "correct_words = [\"benign-hypertension\", \"morbid-obesity\", \"bird\", \"fish\", \"dog\", \"potassium\"]\n",
    "incorrect_words = [\"morpidopesity\", \"dag\", \"besignhypertension\", \"fush\", \"patision\"]\n",
    "\n",
    "for iw in incorrect_words:\n",
    "    nearest_match = difflib.get_close_matches(iw, correct_words)\n",
    "    if nearest_match:\n",
    "        nearest_match1 = nearest_match\n",
    "        print(f\"The nearest match for {iw} is {nearest_match1}\")\n",
    "    else:\n",
    "        print(f\"{iw}\")\n",
    "\n",
    "def nearest_match(word, word_list):\n",
    "    distances = []\n",
    "    for w in word_list:\n",
    "        distances.append((w, lev.distance(word, w)))\n",
    "    return min(distances, key=lambda x: x[1])\n",
    "\n",
    "# Example usage\n",
    "word_list = [\"benign-hypertension\",\"morbid-obesity\",\"hyperlipidemia\", \"hypertension\", \"potassium\"]\n",
    "nearest_word = list(nearest_match(iw, correct_words))\n",
    "print(f\"The nearest match for {iw} is {nearest_word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "732a02ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results not found in API response\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Endpoint for the FDA open API for drug names\n",
    "url = 'https://api.fda.gov/drug/label.json?search=openfda.brand_name.exists:true'\n",
    "\n",
    "# Initialize an empty list to store the drug names\n",
    "drug_names = []\n",
    "\n",
    "while url:\n",
    "    # Send a GET request to the FDA open API and retrieve the JSON data\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    \n",
    "    # Extract the drug names from the JSON data and append them to the list\n",
    "    if 'results' in data:\n",
    "        for item in data['results']:\n",
    "            if 'openfda' in item and 'brand_name' in item['openfda']:\n",
    "                drug_names.append(item['openfda']['brand_name'][0])\n",
    "    else:\n",
    "        print(\"results not found in API response\")\n",
    "        break\n",
    "    # Get the next page of results\n",
    "    if 'next' in data['meta']:\n",
    "        url = data['meta']['next']\n",
    "    else:\n",
    "        url = None\n",
    "\n",
    "print(drug_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d79d29a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a109a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ca408820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_match(word_list, reference_list):\n",
    "    result = {}\n",
    "    for w in word_list:\n",
    "        if w in reference_list:  # check if word is already in reference_list\n",
    "            result[w] = (w, 0)\n",
    "        else:\n",
    "            distances = []\n",
    "            for r in reference_list:\n",
    "                distances.append((r, lev.distance(w, r)))\n",
    "            result[w] = min(distances, key=lambda x: x[1])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d0fd86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3381e121",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
